{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcafT5T1jCK7Pk8+WeZjwv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xX4mx8eeXvK",
        "outputId": "20a6de5b-3ef5-4e00-f365-58ec2be40508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 20 14:28:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# パッケージのインストール\n",
        "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install pytorch_lightning tensorboard==2.9.1 omegaconf einops taming-transformers==0.0.1 clip transformers kornia test-tube\n",
        "!pip install diffusers invisible-watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-8DgEiotekNy",
        "outputId": "f55aa7d5-8887-4791-9000-9ceadb65ec2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining taming-transformers from git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
            "  Cloning https://github.com/CompVis/taming-transformers.git (to revision master) to ./src/taming-transformers\n",
            "  Running command git clone -q https://github.com/CompVis/taming-transformers.git /content/src/taming-transformers\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from taming-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from taming-transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from taming-transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->taming-transformers) (4.1.1)\n",
            "Installing collected packages: taming-transformers\n",
            "  Running setup.py develop for taming-transformers\n",
            "Successfully installed taming-transformers-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.8.2-py3-none-any.whl (798 kB)\n",
            "\u001b[K     |████████████████████████████████| 798 kB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard==2.9.1 in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 464 kB/s \n",
            "\u001b[?25hRequirement already satisfied: taming-transformers==0.0.1 in ./src/taming-transformers (0.0.1)\n",
            "Collecting clip\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 52.2 MB/s \n",
            "\u001b[?25hCollecting kornia\n",
            "  Downloading kornia-0.6.8-py2.py3-none-any.whl (551 kB)\n",
            "\u001b[K     |████████████████████████████████| 551 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting test-tube\n",
            "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (1.50.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (1.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (0.38.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (2.14.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (4.64.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.9.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.9.1) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.9.1) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.9.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1) (3.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.10.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting lightning-utilities==0.3.*\n",
            "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 52.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from test-tube) (1.3.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from test-tube) (2.9.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from test-tube) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->test-tube) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->test-tube) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->test-tube) (2.8.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, clip, test-tube, fire\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144576 sha256=7bf9d7f5e0b0af23c40dfa60ef5c5db2231f775c61fc8ac2063ab766c1c96f2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=7005 sha256=4195ce536a9a5a022d89e174f6c9b7380967c011fa9000ef918941b026ab3385\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/09/22/2a08ba22ac0a9939e09ca9651cbc83fd781894f4b24df79a1b\n",
            "  Building wheel for test-tube (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25357 sha256=75ef0cd456df7a4ac33e1f032cf019ee9f433135f27ced20afb0c29d3447b011\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/50/0d/15b3236957cc18a5c39ec4d4d4d21624f4d4a876756ec17064\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115940 sha256=b2be7c53c0436af310221f4250200b74848399cd0fd51cf41f29233d7a65fafb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built antlr4-python3-runtime clip test-tube fire\n",
            "Installing collected packages: fire, torchmetrics, tokenizers, lightning-utilities, huggingface-hub, antlr4-python3-runtime, transformers, test-tube, pytorch-lightning, omegaconf, kornia, einops, clip\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 clip-0.2.0 einops-0.6.0 fire-0.4.0 huggingface-hub-0.11.0 kornia-0.6.8 lightning-utilities-0.3.0 omegaconf-2.2.3 pytorch-lightning-1.8.2 test-tube-0.7.5 tokenizers-0.13.2 torchmetrics-0.10.3 transformers-4.24.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.7.2-py3-none-any.whl (304 kB)\n",
            "\u001b[K     |████████████████████████████████| 304 kB 15.8 MB/s \n",
            "\u001b[?25hCollecting invisible-watermark\n",
            "  Downloading invisible_watermark-0.1.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from diffusers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from diffusers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from diffusers) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from diffusers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from diffusers) (2022.6.2)\n",
            "Requirement already satisfied: Pillow<10.0 in /usr/local/lib/python3.7/dist-packages (from diffusers) (7.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from diffusers) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.10.0->diffusers) (3.0.9)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from invisible-watermark) (1.3.0)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.13.1-cp37-cp37m-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from invisible-watermark) (1.12.1+cu113)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from invisible-watermark) (4.6.0.66)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->diffusers) (3.10.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx->invisible-watermark) (3.19.6)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime->invisible-watermark) (1.12)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime->invisible-watermark) (1.7.1)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->diffusers) (1.24.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime->invisible-watermark) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime, onnx, invisible-watermark, diffusers\n",
            "Successfully installed coloredlogs-15.0.1 diffusers-0.7.2 humanfriendly-10.0 invisible-watermark-0.1.5 onnx-1.12.0 onnxruntime-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# StableDiffusion のインストール\n",
        "!git clone https://github.com/CompVis/stable-diffusion.git\n",
        "%cd stable-diffusion\n",
        "!pip install -e .\n",
        "%mkdir outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAgRANmHelEq",
        "outputId": "145f89ed-79c2-4469-d4ab-d25a06ddc7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stable-diffusion'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 42.65 MiB | 22.35 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n",
            "/content/stable-diffusion\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/stable-diffusion\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from latent-diffusion==0.0.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from latent-diffusion==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from latent-diffusion==0.0.1) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->latent-diffusion==0.0.1) (4.1.1)\n",
            "Installing collected packages: latent-diffusion\n",
            "  Running setup.py develop for latent-diffusion\n",
            "Successfully installed latent-diffusion-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Anythingv3.0 のモデルデータを取得\n",
        "!wget https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBxtKj86emoe",
        "outputId": "d0b1828d-f4b1-4ad4-d8b4-4780b38676ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-20 14:30:56--  https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 34.233.26.136, 44.205.155.151, 2600:1f18:147f:e850:a5bf:7d62:cee0:9842, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.233.26.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/1e/ef/1eefd55077badc87cd1798672a058b8d55aeab58e781be883f2ec0e0917679e3/543bcbc21294831c6245cd74c8a7707761e28812c690f946cb81fef930d54b5e?response-content-disposition=attachment%3B%20filename%3D%22Anything-V3.0-pruned.ckpt%22&Expires=1669187140&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzFlL2VmLzFlZWZkNTUwNzdiYWRjODdjZDE3OTg2NzJhMDU4YjhkNTVhZWFiNThlNzgxYmU4ODNmMmVjMGUwOTE3Njc5ZTMvNTQzYmNiYzIxMjk0ODMxYzYyNDVjZDc0YzhhNzcwNzc2MWUyODgxMmM2OTBmOTQ2Y2I4MWZlZjkzMGQ1NGI1ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMkFueXRoaW5nLVYzLjAtcHJ1bmVkLmNrcHQlMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NjkxODcxNDB9fX1dfQ__&Signature=ORwHmDR7oBqlNMLJQorJYU7xbukkENOivwzha5QbTGwmwckVMmCaXBDVLnOejsZP9ULVMFbaf4YIDYDqeJFwfknhvpW4LyIb1f5nVkwBQx95LzCin~6fDdibxn4vFZ8xyHmVORbrR1YQABg2M4tw86DZuwk5w9Gm1Pwu~tiukAP~auaj7JGyKgNAOG9XoOO0N27jLuNqJDfNqJLOx~XVVt15y3PszCfolbR0lfsgcr9QZm7zwX5lijYDek13WU0W9SJ8sHZl8ovWXWytguyj9fb6Ky4pRjaX5uCv~liMiHeAlCJP4svoCdwFbkl5EqMOODwmGTZR0E3FKHvXZpSSXQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-11-20 14:30:56--  https://cdn-lfs.huggingface.co/repos/1e/ef/1eefd55077badc87cd1798672a058b8d55aeab58e781be883f2ec0e0917679e3/543bcbc21294831c6245cd74c8a7707761e28812c690f946cb81fef930d54b5e?response-content-disposition=attachment%3B%20filename%3D%22Anything-V3.0-pruned.ckpt%22&Expires=1669187140&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzFlL2VmLzFlZWZkNTUwNzdiYWRjODdjZDE3OTg2NzJhMDU4YjhkNTVhZWFiNThlNzgxYmU4ODNmMmVjMGUwOTE3Njc5ZTMvNTQzYmNiYzIxMjk0ODMxYzYyNDVjZDc0YzhhNzcwNzc2MWUyODgxMmM2OTBmOTQ2Y2I4MWZlZjkzMGQ1NGI1ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMkFueXRoaW5nLVYzLjAtcHJ1bmVkLmNrcHQlMjIiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NjkxODcxNDB9fX1dfQ__&Signature=ORwHmDR7oBqlNMLJQorJYU7xbukkENOivwzha5QbTGwmwckVMmCaXBDVLnOejsZP9ULVMFbaf4YIDYDqeJFwfknhvpW4LyIb1f5nVkwBQx95LzCin~6fDdibxn4vFZ8xyHmVORbrR1YQABg2M4tw86DZuwk5w9Gm1Pwu~tiukAP~auaj7JGyKgNAOG9XoOO0N27jLuNqJDfNqJLOx~XVVt15y3PszCfolbR0lfsgcr9QZm7zwX5lijYDek13WU0W9SJ8sHZl8ovWXWytguyj9fb6Ky4pRjaX5uCv~liMiHeAlCJP4svoCdwFbkl5EqMOODwmGTZR0E3FKHvXZpSSXQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.156.46.84, 108.156.46.127, 108.156.46.2, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.156.46.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3852134462 (3.6G) [binary/octet-stream]\n",
            "Saving to: ‘Anything-V3.0-pruned.ckpt’\n",
            "\n",
            "Anything-V3.0-prune 100%[===================>]   3.59G   245MB/s    in 16s     \n",
            "\n",
            "2022-11-20 14:31:12 (232 MB/s) - ‘Anything-V3.0-pruned.ckpt’ saved [3852134462/3852134462]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# セーフフィルタのチェックをスキップした txt2img.py を txt2img2.py として保存\n",
        "!wget https://gist.githubusercontent.com/uakihir0/bbb1bd8a4480e2bab07726ca0e744f91/raw/3e6f43fa5c112e512006cc9e33e932f6c6539d94/txt2img.py -O scripts/txt2img2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntD6qv-IesFb",
        "outputId": "ce54a4bd-ccdf-46da-a36c-de52c8f3c338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-20 14:31:13--  https://gist.githubusercontent.com/uakihir0/bbb1bd8a4480e2bab07726ca0e744f91/raw/3e6f43fa5c112e512006cc9e33e932f6c6539d94/txt2img.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9339 (9.1K) [text/plain]\n",
            "Saving to: ‘scripts/txt2img2.py’\n",
            "\n",
            "\rscripts/txt2img2.py   0%[                    ]       0  --.-KB/s               \rscripts/txt2img2.py 100%[===================>]   9.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-20 14:31:13 (68.7 MB/s) - ‘scripts/txt2img2.py’ saved [9339/9339]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# realcugan ncnn vulkanの追加\n",
        "!git clone https://github.com/HidemaruOwO/realcugan-ncnn-vulkan-simple\n",
        "!mv realcugan-ncnn-vulkan-simple/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx2uJZuwl7f8",
        "outputId": "1ca6d99e-7cbd-4917-848f-148770e06a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'realcugan-ncnn-vulkan-simple' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# realcugan ncnn vulkanの環境構築\n",
        "#!bash setup.sh\n",
        "#!mv convert.sh convert.sh.tmp\n",
        "!cat convert.sh.tmp | sed -s \"s;baseimg;outputs/samples;\" >> convert.sh\n",
        "!chmod 744 convert.sh\n",
        "!apt install vulkan-utils libvulkan-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pou4RwWpzm13",
        "outputId": "15558d65-bcc3-408a-e2e6-ae772e4f46b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libvulkan-dev is already the newest version (1.1.126.0-2~gpu18.04.1).\n",
            "vulkan-utils is already the newest version (1.1.126.0+dfsg1-1~gpu18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# realcugan-ncnn-vulkanが落とせなかったら直接落とす\n",
        "!wget https://github.com/nihui/realcugan-ncnn-vulkan/releases/download/20220728/realcugan-ncnn-vulkan-20220728-ubuntu.zip\n",
        "!unzip realcugan-ncnn-vulkan-20220728-ubuntu.zip\n",
        "!mv realcugan-ncnn-vulkan-20220728-ubuntu/* bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J89OQVWzo-T",
        "outputId": "719dde3c-4aa3-4890-e2dc-b466b98b89d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-20 16:17:55--  https://github.com/nihui/realcugan-ncnn-vulkan/releases/download/20220728/realcugan-ncnn-vulkan-20220728-ubuntu.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/458695452/c659c1c9-6861-4bd8-a1fd-924fb6f7af5a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221120T161756Z&X-Amz-Expires=300&X-Amz-Signature=c732fbe720a52b8b9ad1ef5ed79836dd09a1af257527eb095a6503fef9ed8b94&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=458695452&response-content-disposition=attachment%3B%20filename%3Drealcugan-ncnn-vulkan-20220728-ubuntu.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-20 16:17:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/458695452/c659c1c9-6861-4bd8-a1fd-924fb6f7af5a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221120T161756Z&X-Amz-Expires=300&X-Amz-Signature=c732fbe720a52b8b9ad1ef5ed79836dd09a1af257527eb095a6503fef9ed8b94&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=458695452&response-content-disposition=attachment%3B%20filename%3Drealcugan-ncnn-vulkan-20220728-ubuntu.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46704187 (45M) [application/octet-stream]\n",
            "Saving to: ‘realcugan-ncnn-vulkan-20220728-ubuntu.zip’\n",
            "\n",
            "realcugan-ncnn-vulk 100%[===================>]  44.54M  20.2MB/s    in 2.2s    \n",
            "\n",
            "2022-11-20 16:17:58 (20.2 MB/s) - ‘realcugan-ncnn-vulkan-20220728-ubuntu.zip’ saved [46704187/46704187]\n",
            "\n",
            "Archive:  realcugan-ncnn-vulkan-20220728-ubuntu.zip\n",
            "   creating: realcugan-ncnn-vulkan-20220728-ubuntu/\n",
            "   creating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/\n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up2x-no-denoise.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up3x-denoise3x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up3x-denoise3x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up3x-conservative.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up3x-conservative.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up2x-no-denoise.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up3x-no-denoise.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up2x-denoise3x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up2x-conservative.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up2x-denoise3x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up3x-no-denoise.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-pro/up2x-conservative.bin  \n",
            "   creating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/\n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-no-denoise.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up3x-denoise3x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-denoise1x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up3x-denoise3x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-denoise2x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up4x-denoise3x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up3x-conservative.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-denoise2x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up3x-conservative.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up4x-conservative.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-no-denoise.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up4x-no-denoise.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-denoise1x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up3x-no-denoise.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up4x-denoise3x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up4x-no-denoise.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-denoise3x.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-conservative.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-denoise3x.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up3x-no-denoise.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up2x-conservative.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-se/up4x-conservative.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/realcugan-ncnn-vulkan  \n",
            "   creating: realcugan-ncnn-vulkan-20220728-ubuntu/models-nose/\n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-nose/up2x-no-denoise.param  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/models-nose/up2x-no-denoise.bin  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/LICENSE  \n",
            "  inflating: realcugan-ncnn-vulkan-20220728-ubuntu/README.md  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# イラストの生成\n",
        "# promptに英単語および英文を羅列させる\n",
        "!python scripts/txt2img2.py \\\n",
        "    --H 704 \\\n",
        "    --W 448 \\\n",
        "    --plms \\\n",
        "    --ckpt ./Anything-V3.0-pruned.ckpt \\\n",
        "    --skip_grid \\\n",
        "    --n_samples 1  \\\n",
        "    --n_iter 1 \\\n",
        "    --outdir outputs \\\n",
        "    --ddim_steps 100 \\\n",
        "    --prompt \"JK high school student black haer eyes cute heart in eyes sleepy lie prone on one's desk\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxylnk6IesqV",
        "outputId": "4e667a4a-e8dc-49ba-ffe7-ae9eae0e7e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 42\n",
            "Loading model from ./Anything-V3.0-pruned.ckpt\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:259: LightningDeprecationWarning: `pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will be removed in v1.10.0. You can import it from `pytorch_lightning.utilities` instead.\n",
            "  \"`pytorch_lightning.utilities.distributed.rank_zero_only` has been deprecated in v1.8.1 and will\"\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.post_layernorm.weight', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'logit_scale', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'visual_projection.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'text_projection.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Sampling:   0% 0/1 [00:00<?, ?it/s]\n",
            "data:   0% 0/1 [00:00<?, ?it/s]\u001b[AData shape for PLMS sampling is (1, 4, 88, 56)\n",
            "Running PLMS Sampling with 100 timesteps\n",
            "\n",
            "\n",
            "PLMS Sampler:   0% 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   1% 1/100 [00:04<06:49,  4.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   2% 2/100 [00:04<03:07,  1.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   3% 3/100 [00:04<01:57,  1.21s/it]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   4% 4/100 [00:05<01:23,  1.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   5% 5/100 [00:05<01:05,  1.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   6% 6/100 [00:05<00:54,  1.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   7% 7/100 [00:06<00:47,  1.97it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   8% 8/100 [00:06<00:42,  2.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:   9% 9/100 [00:07<00:39,  2.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  10% 10/100 [00:07<00:36,  2.44it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  11% 11/100 [00:07<00:35,  2.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  12% 12/100 [00:08<00:34,  2.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  13% 13/100 [00:08<00:33,  2.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  14% 14/100 [00:08<00:32,  2.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  15% 15/100 [00:09<00:31,  2.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  16% 16/100 [00:09<00:31,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  17% 17/100 [00:09<00:30,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  18% 18/100 [00:10<00:30,  2.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  19% 19/100 [00:10<00:29,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  20% 20/100 [00:11<00:29,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  21% 21/100 [00:11<00:28,  2.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  22% 22/100 [00:11<00:28,  2.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  23% 23/100 [00:12<00:28,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  24% 24/100 [00:12<00:27,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  25% 25/100 [00:12<00:27,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  26% 26/100 [00:13<00:27,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  27% 27/100 [00:13<00:26,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  28% 28/100 [00:13<00:26,  2.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  29% 29/100 [00:14<00:26,  2.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  30% 30/100 [00:14<00:25,  2.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  31% 31/100 [00:15<00:25,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  32% 32/100 [00:15<00:25,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  33% 33/100 [00:15<00:24,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  34% 34/100 [00:16<00:24,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  35% 35/100 [00:16<00:23,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  36% 36/100 [00:16<00:23,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  37% 37/100 [00:17<00:23,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  38% 38/100 [00:17<00:22,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  39% 39/100 [00:18<00:22,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  40% 40/100 [00:18<00:22,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  41% 41/100 [00:18<00:21,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  42% 42/100 [00:19<00:21,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  43% 43/100 [00:19<00:21,  2.70it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  44% 44/100 [00:19<00:20,  2.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  45% 45/100 [00:20<00:20,  2.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  46% 46/100 [00:20<00:20,  2.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  47% 47/100 [00:21<00:19,  2.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  48% 48/100 [00:21<00:19,  2.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  49% 49/100 [00:21<00:18,  2.69it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  50% 50/100 [00:22<00:18,  2.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  51% 51/100 [00:22<00:18,  2.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  52% 52/100 [00:22<00:17,  2.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  53% 53/100 [00:23<00:17,  2.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  54% 54/100 [00:23<00:17,  2.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  55% 55/100 [00:24<00:16,  2.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  56% 56/100 [00:24<00:16,  2.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  57% 57/100 [00:24<00:16,  2.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  58% 58/100 [00:25<00:15,  2.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  59% 59/100 [00:25<00:15,  2.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  60% 60/100 [00:25<00:15,  2.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  61% 61/100 [00:26<00:14,  2.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  62% 62/100 [00:26<00:14,  2.65it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  63% 63/100 [00:27<00:14,  2.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  64% 64/100 [00:27<00:13,  2.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  65% 65/100 [00:27<00:13,  2.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  66% 66/100 [00:28<00:12,  2.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  67% 67/100 [00:28<00:12,  2.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  68% 68/100 [00:28<00:12,  2.64it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  69% 69/100 [00:29<00:11,  2.63it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  70% 70/100 [00:29<00:11,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  71% 71/100 [00:30<00:11,  2.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  72% 72/100 [00:30<00:10,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  73% 73/100 [00:30<00:10,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  74% 74/100 [00:31<00:09,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  75% 75/100 [00:31<00:09,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  76% 76/100 [00:32<00:09,  2.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  77% 77/100 [00:32<00:08,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  78% 78/100 [00:32<00:08,  2.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  79% 79/100 [00:33<00:08,  2.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  80% 80/100 [00:33<00:07,  2.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  81% 81/100 [00:33<00:07,  2.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  82% 82/100 [00:34<00:06,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  83% 83/100 [00:34<00:06,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  84% 84/100 [00:35<00:06,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  85% 85/100 [00:35<00:05,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  86% 86/100 [00:35<00:05,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  87% 87/100 [00:36<00:05,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  88% 88/100 [00:36<00:04,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  89% 89/100 [00:37<00:04,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  90% 90/100 [00:37<00:03,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  91% 91/100 [00:37<00:03,  2.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  92% 92/100 [00:38<00:03,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  93% 93/100 [00:38<00:02,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  94% 94/100 [00:38<00:02,  2.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  95% 95/100 [00:39<00:01,  2.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  96% 96/100 [00:39<00:01,  2.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  97% 97/100 [00:40<00:01,  2.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  98% 98/100 [00:40<00:00,  2.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler:  99% 99/100 [00:40<00:00,  2.58it/s]\u001b[A\u001b[A\n",
            "\n",
            "PLMS Sampler: 100% 100/100 [00:41<00:00,  2.42it/s]\n",
            "\n",
            "data: 100% 1/1 [00:44<00:00, 44.44s/it]\n",
            "Sampling: 100% 1/1 [00:44<00:00, 44.44s/it]\n",
            "Your samples are ready and waiting for you here: \n",
            "outputs \n",
            " \n",
            "Enjoy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成した画像のアップスケーリング\n",
        "# 第一引数: 拡大率\n",
        "# 第二引数: ノイズ除去の強度\n",
        "!bash convert.sh 3 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV2wr9_8zw4A",
        "outputId": "d16a724f-5b5b-4fe3-f34c-c4f2dc75ac3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running realcugan-ncnn-vulkan.\n",
            "Scale: 3\n",
            "Noise: 3\n",
            "Checking for existing files.\n",
            "bin exists.\n",
            "outputs/samples exists.\n",
            "dist exists.\n",
            "realcugan-ncnn-vulkan exists.\n",
            "\u001b[33mConverting...\u001b[m\n",
            "./outputs/samples/00000.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00001.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00002.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00003.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00004.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00005.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00006.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00007.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00008.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00009.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00010.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00011.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00012.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00013.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00014.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00015.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00016.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00017.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "./outputs/samples/00018.png\n",
            "[0 Tesla T4]  queueC=2[8]  queueG=0[16]  queueT=1[2]\n",
            "[0 Tesla T4]  bugsbn1=0  bugbilz=0  bugcopc=0  bugihfa=0\n",
            "[0 Tesla T4]  fp16-p/s/a=1/1/1  int8-p/s/a=1/1/1\n",
            "[0 Tesla T4]  subgroup=32  basic=1  vote=1  ballot=1  shuffle=1\n",
            "\u001b[32mConverted\u001b[m\n",
            "\u001b[36mDone.\u001b[m\n"
          ]
        }
      ]
    }
  ]
}